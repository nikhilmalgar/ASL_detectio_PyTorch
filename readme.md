# ğŸ¤Ÿ ASL Hand Sign Recognition using PyTorch

This project is a real-time American Sign Language (ASL) hand sign recognition system built using **PyTorch**, **OpenCV**, and **Streamlit**. It supports webcam input and gives voice feedback for the predicted signs. The model is trained on the **ASL Alphabet Dataset** and integrated into a lightweight, user-friendly app.

---

## ğŸš€ Features

- ğŸ” Real-time ASL hand sign detection via webcam
- ğŸ§  PyTorch-based CNN model
- ğŸ“¦ Streamlit UI for live interaction
- ğŸ”Š Voice output using `pyttsx3`
- ğŸ“ˆ Training & evaluation scripts included
- ğŸ“Š Accuracy reporting and visualization
- ğŸ’¾ Save & load trained model checkpoints

---

## ğŸ“‚ Project Structure

ASL_HANDSIGN_PYTORCH/
â”‚
â”œâ”€â”€ app/ # Streamlit app with real-time webcam prediction
â”‚ â””â”€â”€ app.py
â”‚
â”œâ”€â”€ src/ # Source files for the model and dataloader
â”‚ â”œâ”€â”€ dataset.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â””â”€â”€ model.py
â”‚
â”œâ”€â”€ data/ # Dataset and model checkpoints
â”‚ â”œâ”€â”€ asl_alphabet_train/
â”‚ â”œâ”€â”€ asl_alphabet_test/
â”‚ â””â”€â”€ saved_models/
â”‚
â”œâ”€â”€ train.py # Training script
â”œâ”€â”€ test_dataloader.py # Data loading test script
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .gitignore # Files to ignore in Git

---

## ğŸ› ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/ASL_HANDSIGN_PYTORCH.git
cd ASL_HANDSIGN_PYTORCH

## 2. Create and activate a virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

#3. Install dependencies
pip install -r requirements.txt

ğŸ“ Dataset Setup
Download the ASL Alphabet Dataset from Kaggle:
ğŸ”— https://www.kaggle.com/datasets/grassknoted/asl-alphabet

After downloading and extracting:

Place training data inside:

bash
Copy
Edit
data/asl_alphabet_train/
Place test data inside:

bash
Copy
Edit
data/asl_alphabet_test/
âš ï¸ The dataset is not included in the repo due to size.

ğŸ§  Model Training
To train the model on your local machine:

bash
Copy
Edit
python train.py
After training, the model will be saved at:

bash
Copy
Edit
data/saved_models/asl_model.pth
ğŸ§ª Test DataLoader
Check if dataset is loading correctly:

bash
Copy
Edit
python test_dataloader.py
ğŸ¯ Evaluate the Model
Use evaluate.py to get test accuracy:

bash
Copy
Edit
python src/evaluate.py
ğŸŒ Run the Real-Time Streamlit App
Launch the web app:

bash
Copy
Edit
streamlit run app/app.py
The webcam will turn on. Show ASL signs one at a time to get predictions with audio feedback.

ğŸ”Š Voice Output
Voice output is powered by pyttsx3.

For Linux, install this additional package if needed:

bash
Copy
Edit
sudo apt-get install espeak
ğŸ“ .gitignore Example
Hereâ€™s a sample .gitignore for your repo:

bash
Copy
Edit
__pycache__/
*.pyc
*.pth
*.log
venv/
*.DS_Store
data/saved_models/
data/asl_alphabet_train/
data/asl_alphabet_test/
ğŸ’¡ Tips
Make sure your hand is clearly visible to the webcam

Use plain backgrounds and good lighting

Use same size/image orientation as dataset samples

Train for more epochs or augment the dataset to improve accuracy

ğŸ“ƒ License
This project is licensed under the MIT License.

ğŸ™‹â€â™‚ï¸ Author
Nikhil Malagar
B.Tech in CSE (AI & ML)
Passionate about AI, Deep Learning, and Full-Stack Development
ğŸ”— GitHub: @nikhilmalgar

â­ Support
If you find this project useful, please consider giving it a â­ on GitHub. Thank you! ğŸ˜Š


```
